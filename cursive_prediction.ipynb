{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.0+cu117\n",
      "0.14.0+cu117\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "folder_path = 'C:/Users/siddu/SU22_project/cursive_prediction/datafileszipped/datafiles'\n",
    "os.chdir(folder_path)\n",
    "files_in_folder = os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dic = {}\n",
    "for file in files_in_folder:\n",
    "    letter = file[-5]\n",
    "    file_dic[file] = letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(file_dic.items()), columns=['file_name', 'letter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>letter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000_a.png</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001_b.png</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0002_n.png</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_o.png</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_e.png</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1935</th>\n",
       "      <td>1935_i.png</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1936</th>\n",
       "      <td>1936_x.png</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1937</th>\n",
       "      <td>1937_o.png</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1938</th>\n",
       "      <td>1938_l.png</td>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1939</th>\n",
       "      <td>1939_r.png</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1940 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       file_name letter\n",
       "0     0000_a.png      a\n",
       "1     0001_b.png      b\n",
       "2     0002_n.png      n\n",
       "3     0003_o.png      o\n",
       "4     0004_e.png      e\n",
       "...          ...    ...\n",
       "1935  1935_i.png      i\n",
       "1936  1936_x.png      x\n",
       "1937  1937_o.png      o\n",
       "1938  1938_l.png      l\n",
       "1939  1939_r.png      r\n",
       "\n",
       "[1940 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "IMG_SIZE = 64\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def png_to_tensor(path):\n",
    "    # Replace 'path_to_image.png' with the actual path to your PNG file\n",
    "    image_path = folder_path + '/' + path\n",
    "\n",
    "    # Open the image\n",
    "    image = Image.open(image_path)\n",
    "    bw_image = image.convert('L')\n",
    "    data_transforms = [\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.ToTensor(), # Scales data into [0,1] \n",
    "        transforms.Lambda(lambda t: (t * 2) - 1) # Scale between [-1, 1] \n",
    "    ]\n",
    "    data_transform = transforms.Compose(data_transforms)\n",
    "    img_tensor = data_transform(bw_image)\n",
    "\n",
    "\n",
    "    return img_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION TO ADD NOISE \n",
    "def add_gaussian_noise(tensor, mean=0.0, std=0.1):\n",
    "    noise = torch.randn(tensor.size()) * std + mean\n",
    "    noisy_tensor = tensor + noise\n",
    "    return torch.clamp(noisy_tensor, min=-1.0, max=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMAGE TO NOISY TENSOR\n",
    "def png_to_noisy_tensor(path, noise_mean=0.0, noise_std=0.1):\n",
    "    # Replace 'path_to_image.png' with the actual path to your PNG file\n",
    "    image_path = folder_path + '/' + path\n",
    "\n",
    "    # Open the image\n",
    "    image = Image.open(image_path)\n",
    "    bw_image = image.convert('L')\n",
    "    data_transforms = [\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.ToTensor(), # Scales data into [0,1] \n",
    "        transforms.Lambda(lambda t: (t * 2) - 1) # Scale between [-1, 1] \n",
    "    ]\n",
    "    data_transform = transforms.Compose(data_transforms)\n",
    "    img_tensor = data_transform(bw_image)\n",
    "\n",
    "    # Add Gaussian noise to the tensor\n",
    "    noisy_img_tensor = add_gaussian_noise(img_tensor, mean=noise_mean, std=noise_std)\n",
    "\n",
    "    return noisy_img_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_tensor_image(tensor):\n",
    "    reverse_transforms = transforms.Compose([\n",
    "        transforms.Lambda(lambda t: (t + 1) / 2),\n",
    "        transforms.Lambda(lambda t: t.permute(1, 2, 0)), # CHW to HWC\n",
    "        transforms.Lambda(lambda t: t * 255.),\n",
    "        transforms.Lambda(lambda t: t.numpy().astype(np.uint8)),\n",
    "        transforms.ToPILImage(),\n",
    "    ])\n",
    "    return reverse_transforms(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['image'] = df['file_name'].apply(png_to_tensor)\n",
    "df.drop(columns = ['file_name'], inplace = True)\n",
    "df = df[['image', 'letter']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>letter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[tensor(0.5608), tensor(0.5843), tensor(0.66...</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[tensor(0.5451), tensor(0.5529), tensor(0.56...</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[tensor(0.6784), tensor(0.7020), tensor(0.67...</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[[tensor(0.6706), tensor(0.6549), tensor(0.63...</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[[tensor(0.6863), tensor(0.6784), tensor(0.67...</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1935</th>\n",
       "      <td>[[[tensor(0.6706), tensor(0.6627), tensor(0.64...</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1936</th>\n",
       "      <td>[[[tensor(0.6627), tensor(0.6627), tensor(0.67...</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1937</th>\n",
       "      <td>[[[tensor(0.6000), tensor(0.6078), tensor(0.63...</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1938</th>\n",
       "      <td>[[[tensor(0.6235), tensor(0.6235), tensor(0.63...</td>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1939</th>\n",
       "      <td>[[[tensor(0.6549), tensor(0.6392), tensor(0.62...</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1940 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  image letter\n",
       "0     [[[tensor(0.5608), tensor(0.5843), tensor(0.66...      a\n",
       "1     [[[tensor(0.5451), tensor(0.5529), tensor(0.56...      b\n",
       "2     [[[tensor(0.6784), tensor(0.7020), tensor(0.67...      n\n",
       "3     [[[tensor(0.6706), tensor(0.6549), tensor(0.63...      o\n",
       "4     [[[tensor(0.6863), tensor(0.6784), tensor(0.67...      e\n",
       "...                                                 ...    ...\n",
       "1935  [[[tensor(0.6706), tensor(0.6627), tensor(0.64...      i\n",
       "1936  [[[tensor(0.6627), tensor(0.6627), tensor(0.67...      x\n",
       "1937  [[[tensor(0.6000), tensor(0.6078), tensor(0.63...      o\n",
       "1938  [[[tensor(0.6235), tensor(0.6235), tensor(0.63...      l\n",
       "1939  [[[tensor(0.6549), tensor(0.6392), tensor(0.62...      r\n",
       "\n",
       "[1940 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    noise_df = df2.copy()\n",
    "    noise_df['image'] = noise_df['file_name'].apply(png_to_noisy_tensor)\n",
    "    noise_df.drop(columns = ['file_name'], inplace = True)\n",
    "    noise_df = noise_df[['image', 'letter']]\n",
    "    df = pd.concat([df, noise_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>letter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[tensor(0.5608), tensor(0.5843), tensor(0.66...</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[tensor(0.5451), tensor(0.5529), tensor(0.56...</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[tensor(0.6784), tensor(0.7020), tensor(0.67...</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[[tensor(0.6706), tensor(0.6549), tensor(0.63...</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[[tensor(0.6863), tensor(0.6784), tensor(0.67...</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1935</th>\n",
       "      <td>[[[tensor(0.5413), tensor(0.6765), tensor(0.64...</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1936</th>\n",
       "      <td>[[[tensor(0.5499), tensor(0.6307), tensor(0.71...</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1937</th>\n",
       "      <td>[[[tensor(0.6085), tensor(0.3713), tensor(0.47...</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1938</th>\n",
       "      <td>[[[tensor(0.5232), tensor(0.5870), tensor(0.70...</td>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1939</th>\n",
       "      <td>[[[tensor(0.7093), tensor(0.6054), tensor(0.76...</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21340 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  image letter\n",
       "0     [[[tensor(0.5608), tensor(0.5843), tensor(0.66...      a\n",
       "1     [[[tensor(0.5451), tensor(0.5529), tensor(0.56...      b\n",
       "2     [[[tensor(0.6784), tensor(0.7020), tensor(0.67...      n\n",
       "3     [[[tensor(0.6706), tensor(0.6549), tensor(0.63...      o\n",
       "4     [[[tensor(0.6863), tensor(0.6784), tensor(0.67...      e\n",
       "...                                                 ...    ...\n",
       "1935  [[[tensor(0.5413), tensor(0.6765), tensor(0.64...      i\n",
       "1936  [[[tensor(0.5499), tensor(0.6307), tensor(0.71...      x\n",
       "1937  [[[tensor(0.6085), tensor(0.3713), tensor(0.47...      o\n",
       "1938  [[[tensor(0.5232), tensor(0.5870), tensor(0.70...      l\n",
       "1939  [[[tensor(0.7093), tensor(0.6054), tensor(0.76...      r\n",
       "\n",
       "[21340 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "# df to tuples\n",
    "data_tuples = list(zip(df['image'].tolist(), df['letter'].tolist()))\n",
    "\n",
    "# Split indices\n",
    "dataset_size = len(data_tuples)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(0.2 * dataset_size)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Shuffle indices\n",
    "indices_shuffled = torch.randperm(len(indices))\n",
    "\n",
    "# Split \n",
    "train_indices, test_indices = indices_shuffled[split:], indices_shuffled[:split]\n",
    "\n",
    "# custom Dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_tensor, letter = self.data[index]\n",
    "        return image_tensor, ord(letter) - ord('a')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "# custom Datasets\n",
    "train_dataset = CustomDataset(data=[data_tuples[i] for i in train_indices])\n",
    "test_dataset = CustomDataset(data=[data_tuples[i] for i in test_indices])\n",
    "\n",
    "#  DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X batch: tensor([[[[0.9633, 0.7800, 0.7885,  ..., 0.9929, 1.0000, 0.8275],\n",
      "          [0.9061, 1.0000, 0.8815,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [0.8827, 0.9692, 0.9823,  ..., 1.0000, 0.9047, 1.0000],\n",
      "          ...,\n",
      "          [1.0000, 0.9631, 0.7805,  ..., 0.9368, 0.8677, 0.9429],\n",
      "          [0.7482, 1.0000, 0.9075,  ..., 1.0000, 0.9974, 0.8434],\n",
      "          [0.9015, 0.8534, 0.9147,  ..., 0.8314, 1.0000, 0.9050]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 1.0000, 1.0000,  ..., 1.0000, 0.9411, 0.9629],\n",
      "          [0.7876, 1.0000, 1.0000,  ..., 0.9686, 1.0000, 0.9964],\n",
      "          [0.9364, 0.8613, 1.0000,  ..., 1.0000, 1.0000, 0.8520],\n",
      "          ...,\n",
      "          [0.8087, 0.9351, 0.9440,  ..., 0.9332, 1.0000, 0.9627],\n",
      "          [0.9825, 0.9668, 0.9852,  ..., 0.8212, 0.8582, 0.7907],\n",
      "          [0.8098, 0.8525, 1.0000,  ..., 0.7390, 0.8902, 0.8726]]],\n",
      "\n",
      "\n",
      "        [[[0.5030, 0.5592, 0.6912,  ..., 0.9561, 0.5438, 0.7189],\n",
      "          [0.5664, 0.6230, 0.4967,  ..., 0.7679, 0.6589, 0.4940],\n",
      "          [0.4906, 0.8707, 0.6168,  ..., 0.7327, 0.6819, 0.7706],\n",
      "          ...,\n",
      "          [0.7060, 0.3792, 0.5822,  ..., 0.6554, 0.6920, 0.5321],\n",
      "          [0.6521, 0.5208, 0.6205,  ..., 0.5076, 0.4816, 0.5476],\n",
      "          [0.4880, 0.6503, 0.8773,  ..., 0.5565, 0.6486, 0.8120]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.8783, 0.7920, 0.9044,  ..., 0.8201, 0.5626, 0.6422],\n",
      "          [0.5841, 0.7868, 0.6678,  ..., 0.5498, 0.7403, 0.6635],\n",
      "          [0.7101, 0.6959, 0.8713,  ..., 0.8255, 0.7961, 0.7658],\n",
      "          ...,\n",
      "          [0.6739, 0.6117, 0.4949,  ..., 0.6875, 0.7516, 0.6818],\n",
      "          [0.7123, 0.6184, 0.4943,  ..., 0.6199, 0.6891, 0.7244],\n",
      "          [0.6020, 0.8885, 0.6872,  ..., 0.7707, 0.6864, 0.7335]]],\n",
      "\n",
      "\n",
      "        [[[0.4261, 0.6086, 0.6842,  ..., 0.6569, 0.5524, 0.5482],\n",
      "          [0.5758, 0.6499, 0.6553,  ..., 0.6005, 0.5559, 0.5607],\n",
      "          [0.7487, 0.6310, 0.5871,  ..., 0.6951, 0.6903, 0.8454],\n",
      "          ...,\n",
      "          [0.6600, 0.5776, 0.5605,  ..., 0.5618, 0.5954, 0.7478],\n",
      "          [0.4893, 0.5379, 0.7852,  ..., 0.5015, 0.6329, 0.7753],\n",
      "          [0.4485, 0.5633, 0.8289,  ..., 0.6338, 0.7261, 0.6593]]],\n",
      "\n",
      "\n",
      "        [[[0.7217, 0.9345, 0.7592,  ..., 0.6976, 0.8124, 0.8128],\n",
      "          [0.9009, 0.7479, 0.7541,  ..., 0.7934, 0.7904, 0.6793],\n",
      "          [0.8302, 0.8905, 0.9726,  ..., 0.8041, 1.0000, 0.9508],\n",
      "          ...,\n",
      "          [0.2931, 0.3446, 0.3046,  ..., 0.4762, 0.2607, 0.3453],\n",
      "          [0.7010, 0.5287, 0.4095,  ..., 0.4131, 0.2682, 0.1651],\n",
      "          [0.6408, 0.7883, 0.7951,  ..., 0.2986, 0.1272, 0.0964]]]])\n",
      "y batch: tensor([14, 18, 17,  7, 19,  3, 14, 20,  4, 20,  4, 20, 24, 14,  0,  5,  5,  2,\n",
      "        12, 12, 11,  7,  0, 13, 12, 11, 14,  4, 10,  0, 18,  0])\n"
     ]
    }
   ],
   "source": [
    "for X_batch, y_batch in test_loader:\n",
    "    print(\"X batch:\", X_batch)\n",
    "    print(\"y batch:\", y_batch)\n",
    "    break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "534"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AlexNet architecture\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_classes=26):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.6157, 0.6235, 0.6235,  ..., 0.6314, 0.6314, 0.6235],\n",
      "          [0.6314, 0.6392, 0.6314,  ..., 0.6314, 0.6235, 0.6157],\n",
      "          [0.6314, 0.6392, 0.6235,  ..., 0.6314, 0.6235, 0.6235],\n",
      "          ...,\n",
      "          [0.6157, 0.6235, 0.6314,  ..., 0.6392, 0.6235, 0.6078],\n",
      "          [0.6314, 0.6314, 0.6314,  ..., 0.6471, 0.6314, 0.6235],\n",
      "          [0.6235, 0.6314, 0.6392,  ..., 0.6392, 0.6392, 0.6392]]],\n",
      "\n",
      "\n",
      "        [[[0.6977, 0.6257, 0.7284,  ..., 0.6942, 0.5811, 0.7750],\n",
      "          [0.6833, 0.7742, 0.5949,  ..., 0.5740, 0.5714, 0.8256],\n",
      "          [0.6571, 0.5698, 0.6884,  ..., 0.5186, 0.4938, 0.2538],\n",
      "          ...,\n",
      "          [0.7125, 0.5852, 0.3265,  ..., 0.6074, 0.5756, 0.6338],\n",
      "          [0.4711, 0.6000, 0.7612,  ..., 0.5138, 0.5671, 0.7145],\n",
      "          [0.7407, 0.6313, 0.4907,  ..., 0.7099, 0.6813, 0.3908]]],\n",
      "\n",
      "\n",
      "        [[[0.7017, 0.6115, 0.7068,  ..., 0.7467, 0.5937, 0.4835],\n",
      "          [0.6620, 0.6337, 0.5716,  ..., 0.5986, 0.6465, 0.5818],\n",
      "          [0.6309, 0.5537, 0.6048,  ..., 0.5412, 0.6735, 0.7159],\n",
      "          ...,\n",
      "          [0.6504, 0.7541, 0.7000,  ..., 0.8649, 0.6031, 0.5626],\n",
      "          [0.7697, 0.5769, 0.7769,  ..., 0.7831, 0.6537, 0.7112],\n",
      "          [0.6783, 0.6745, 0.4927,  ..., 0.7280, 0.6276, 0.6169]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.7314, 0.6384, 0.8183,  ..., 0.6017, 0.6281, 0.6137],\n",
      "          [0.5863, 0.5039, 0.5713,  ..., 0.5511, 0.5426, 0.5711],\n",
      "          [0.5650, 0.5149, 0.5116,  ..., 0.6170, 0.6021, 0.6333],\n",
      "          ...,\n",
      "          [0.5337, 0.4840, 0.6152,  ..., 0.5789, 0.4813, 0.5061],\n",
      "          [0.5207, 0.7195, 0.7299,  ..., 0.5566, 0.4186, 0.5827],\n",
      "          [0.5209, 0.5395, 0.5736,  ..., 0.6544, 0.6748, 0.7526]]],\n",
      "\n",
      "\n",
      "        [[[0.6278, 0.6201, 0.6836,  ..., 0.6943, 0.5712, 0.6371],\n",
      "          [0.7180, 0.5724, 0.6461,  ..., 0.6594, 0.5144, 0.7538],\n",
      "          [0.7392, 0.7570, 0.7887,  ..., 0.4491, 0.4431, 0.6851],\n",
      "          ...,\n",
      "          [0.4719, 0.6484, 0.3569,  ..., 0.6013, 0.6459, 0.7117],\n",
      "          [0.7984, 0.6130, 0.5793,  ..., 0.6413, 0.5737, 0.4205],\n",
      "          [0.6298, 0.7272, 0.7537,  ..., 0.5738, 0.7653, 0.6867]]],\n",
      "\n",
      "\n",
      "        [[[0.6846, 0.4222, 0.6742,  ..., 0.7586, 0.5527, 0.4037],\n",
      "          [0.7685, 0.5463, 0.9378,  ..., 0.8152, 0.6738, 0.5494],\n",
      "          [0.7866, 0.5677, 0.5759,  ..., 0.7516, 0.7590, 0.6867],\n",
      "          ...,\n",
      "          [0.5002, 0.6721, 0.5685,  ..., 0.6597, 0.6778, 0.7569],\n",
      "          [0.7688, 0.6570, 0.6338,  ..., 0.6620, 0.7093, 0.7974],\n",
      "          [0.7549, 0.6331, 0.5417,  ..., 0.7499, 0.7923, 0.7613]]]])\n",
      "tensor([10, 22,  3,  3,  7,  0, 19, 13, 18,  2,  7, 13,  6, 20, 11, 14, 24, 12,\n",
      "        11,  0, 17,  2, 19,  4,  4, 17, 22, 23,  4, 17, 14, 19])\n"
     ]
    }
   ],
   "source": [
    "for i, (inputs, labels) in enumerate(train_loader):\n",
    "    print(inputs)\n",
    "    print(labels)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddu\\AppData\\Local\\Temp\\ipykernel_20496\\2453823309.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels, dtype=torch.long).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.749991363130705\n",
      "Epoch 2, Loss: 1.4550473125239882\n",
      "Epoch 3, Loss: 0.5521483190413494\n",
      "Epoch 4, Loss: 0.2850508477559753\n",
      "Epoch 5, Loss: 0.17696214255341416\n",
      "Epoch 6, Loss: 0.0983422288114893\n",
      "Epoch 7, Loss: 0.061378138346840846\n",
      "Epoch 8, Loss: 0.03474480204366979\n",
      "Epoch 9, Loss: 0.011918613272372269\n",
      "Epoch 10, Loss: 0.029423709331345985\n",
      "Training Finished\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "alexnet = AlexNet().to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(alexnet.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        \n",
    "        labels = torch.tensor(labels, dtype=torch.long).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = alexnet(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "print(\"Training Finished\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddu\\AppData\\Local\\Temp\\ipykernel_20496\\3622266950.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels, dtype=torch.long).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0002695374190325446\n",
      "Testing Finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_loss = 0.0\n",
    "\n",
    "alexnet.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, labels) in enumerate(test_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = torch.tensor(labels, dtype=torch.long).to(device)\n",
    "\n",
    "        outputs = alexnet(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "    print(f\"Test Loss: {test_loss/len(test_loader)}\")\n",
    "\n",
    "print(\"Testing Finished\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['image'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(x):\n",
    "    alexnet.eval()\n",
    "    with torch.no_grad():\n",
    "        input_image = x\n",
    "        output = alexnet(input_image)\n",
    "        \n",
    "    class_labels = np.unique(df['letter'])\n",
    "\n",
    "    predicted_class_index = output.argmax().item()\n",
    "\n",
    "    predicted_class_label = class_labels[predicted_class_index]\n",
    "\n",
    "    print(f\"Predicted Class: {predicted_class_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
