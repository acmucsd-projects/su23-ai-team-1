{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.0+cu117\n",
      "0.14.0+cu117\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "folder_path = 'C:/Users/siddu/SU22_project/cursive_prediction/datafileszipped/datafiles'\n",
    "os.chdir(folder_path)\n",
    "files_in_folder = os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dic = {}\n",
    "for file in files_in_folder:\n",
    "    letter = file[-5]\n",
    "    file_dic[file] = letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(file_dic.items()), columns=['file_name', 'letter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>letter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000_a.png</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001_b.png</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0002_n.png</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_o.png</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_e.png</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1935</th>\n",
       "      <td>1935_i.png</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1936</th>\n",
       "      <td>1936_x.png</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1937</th>\n",
       "      <td>1937_o.png</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1938</th>\n",
       "      <td>1938_l.png</td>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1939</th>\n",
       "      <td>1939_r.png</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1940 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       file_name letter\n",
       "0     0000_a.png      a\n",
       "1     0001_b.png      b\n",
       "2     0002_n.png      n\n",
       "3     0003_o.png      o\n",
       "4     0004_e.png      e\n",
       "...          ...    ...\n",
       "1935  1935_i.png      i\n",
       "1936  1936_x.png      x\n",
       "1937  1937_o.png      o\n",
       "1938  1938_l.png      l\n",
       "1939  1939_r.png      r\n",
       "\n",
       "[1940 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "IMG_SIZE = 64\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def png_to_tensor(path):\n",
    "    # Replace 'path_to_image.png' with the actual path to your PNG file\n",
    "    image_path = folder_path + '/' + path\n",
    "\n",
    "    # Open the image\n",
    "    image = Image.open(image_path)\n",
    "    bw_image = image.convert('L')\n",
    "    data_transforms = [\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.ToTensor(), # Scales data into [0,1] \n",
    "        transforms.Lambda(lambda t: (t * 2) - 1) # Scale between [-1, 1] \n",
    "    ]\n",
    "    data_transform = transforms.Compose(data_transforms)\n",
    "    img_tensor = data_transform(bw_image)\n",
    "\n",
    "\n",
    "    return img_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION TO ADD NOISE \n",
    "def add_gaussian_noise(tensor, mean=0.0, std=0.1):\n",
    "    noise = torch.randn(tensor.size()) * std + mean\n",
    "    noisy_tensor = tensor + noise\n",
    "    return torch.clamp(noisy_tensor, min=-1.0, max=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMAGE TO NOISY TENSOR\n",
    "def png_to_noisy_tensor(path, noise_mean=0.0, noise_std=0.1):\n",
    "    # Replace 'path_to_image.png' with the actual path to your PNG file\n",
    "    image_path = folder_path + '/' + path\n",
    "\n",
    "    # Open the image\n",
    "    image = Image.open(image_path)\n",
    "    bw_image = image.convert('L')\n",
    "    data_transforms = [\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.ToTensor(), # Scales data into [0,1] \n",
    "        transforms.Lambda(lambda t: (t * 2) - 1) # Scale between [-1, 1] \n",
    "    ]\n",
    "    data_transform = transforms.Compose(data_transforms)\n",
    "    img_tensor = data_transform(bw_image)\n",
    "\n",
    "    # Add Gaussian noise to the tensor\n",
    "    noisy_img_tensor = add_gaussian_noise(img_tensor, mean=noise_mean, std=noise_std)\n",
    "\n",
    "    return noisy_img_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_tensor_image(tensor):\n",
    "    reverse_transforms = transforms.Compose([\n",
    "        transforms.Lambda(lambda t: (t + 1) / 2),\n",
    "        transforms.Lambda(lambda t: t.permute(1, 2, 0)), # CHW to HWC\n",
    "        transforms.Lambda(lambda t: t * 255.),\n",
    "        transforms.Lambda(lambda t: t.numpy().astype(np.uint8)),\n",
    "        transforms.ToPILImage(),\n",
    "    ])\n",
    "    return reverse_transforms(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>letter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000_a.png</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001_b.png</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0002_n.png</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_o.png</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_e.png</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1935</th>\n",
       "      <td>1935_i.png</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1936</th>\n",
       "      <td>1936_x.png</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1937</th>\n",
       "      <td>1937_o.png</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1938</th>\n",
       "      <td>1938_l.png</td>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1939</th>\n",
       "      <td>1939_r.png</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1940 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       file_name letter\n",
       "0     0000_a.png      a\n",
       "1     0001_b.png      b\n",
       "2     0002_n.png      n\n",
       "3     0003_o.png      o\n",
       "4     0004_e.png      e\n",
       "...          ...    ...\n",
       "1935  1935_i.png      i\n",
       "1936  1936_x.png      x\n",
       "1937  1937_o.png      o\n",
       "1938  1938_l.png      l\n",
       "1939  1939_r.png      r\n",
       "\n",
       "[1940 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['image'] = df['file_name'].apply(png_to_tensor)\n",
    "df.drop(columns = ['file_name'], inplace = True)\n",
    "df = df[['image', 'letter']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5608, 0.5843, 0.6627,  ..., 0.6784, 0.6392, 0.5922],\n",
       "         [0.5373, 0.5843, 0.6549,  ..., 0.6706, 0.6392, 0.6000],\n",
       "         [0.4980, 0.5529, 0.6078,  ..., 0.6471, 0.6235, 0.6000],\n",
       "         ...,\n",
       "         [0.7333, 0.7255, 0.7020,  ..., 0.7333, 0.7647, 0.7725],\n",
       "         [0.7176, 0.7255, 0.7176,  ..., 0.7412, 0.7647, 0.7725],\n",
       "         [0.7176, 0.7255, 0.7255,  ..., 0.7412, 0.7647, 0.7725]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['image'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5608, 0.5843, 0.6627,  ..., 0.6784, 0.6392, 0.5922],\n",
       "         [0.5373, 0.5843, 0.6549,  ..., 0.6706, 0.6392, 0.6000],\n",
       "         [0.4980, 0.5529, 0.6078,  ..., 0.6471, 0.6235, 0.6000],\n",
       "         ...,\n",
       "         [0.7333, 0.7255, 0.7020,  ..., 0.7333, 0.7647, 0.7725],\n",
       "         [0.7176, 0.7255, 0.7176,  ..., 0.7412, 0.7647, 0.7725],\n",
       "         [0.7176, 0.7255, 0.7255,  ..., 0.7412, 0.7647, 0.7725]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['image'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    noise_df = df2.copy()\n",
    "    noise_df['image'] = noise_df['file_name'].apply(png_to_noisy_tensor)\n",
    "    noise_df.drop(columns = ['file_name'], inplace = True)\n",
    "    noise_df = noise_df[['image', 'letter']]    \n",
    "    df = df.append(noise_df, ignore_index= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "# df to tuples\n",
    "data_tuples = list(zip(df['image'].tolist(), df['letter'].tolist()))\n",
    "\n",
    "# Split indices\n",
    "dataset_size = len(data_tuples)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(0.2 * dataset_size)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Shuffle indices\n",
    "indices_shuffled = torch.randperm(len(indices))\n",
    "\n",
    "# Split \n",
    "train_indices, test_indices = indices_shuffled[split:], indices_shuffled[:split]\n",
    "\n",
    "# custom Dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_tensor, letter = self.data[index]\n",
    "        return image_tensor, ord(letter) - ord('a')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "# custom Datasets\n",
    "train_dataset = CustomDataset(data=[data_tuples[i] for i in train_indices])\n",
    "test_dataset = CustomDataset(data=[data_tuples[i] for i in test_indices])\n",
    "\n",
    "#  DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X batch: tensor([[[[0.9920, 0.8618, 0.8936,  ..., 0.9124, 1.0000, 0.8647],\n",
      "          [0.8649, 1.0000, 0.8967,  ..., 1.0000, 1.0000, 0.9845],\n",
      "          [1.0000, 0.9862, 1.0000,  ..., 0.8917, 0.9107, 0.7749],\n",
      "          ...,\n",
      "          [0.8898, 1.0000, 0.9452,  ..., 0.8701, 0.8830, 0.8917],\n",
      "          [1.0000, 0.9821, 1.0000,  ..., 0.7221, 0.9122, 0.8981],\n",
      "          [0.7282, 0.8308, 0.9136,  ..., 0.8818, 0.9985, 1.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.9079, 0.8628, 0.7311,  ..., 1.0000, 1.0000, 0.9229],\n",
      "          [0.9372, 1.0000, 1.0000,  ..., 1.0000, 0.8420, 1.0000],\n",
      "          [0.9896, 0.8820, 1.0000,  ..., 0.9811, 0.8990, 0.9220],\n",
      "          ...,\n",
      "          [0.9321, 0.9100, 0.8139,  ..., 0.7332, 0.9023, 0.7061],\n",
      "          [1.0000, 0.8448, 0.9104,  ..., 0.7805, 0.8332, 0.9980],\n",
      "          [0.9145, 1.0000, 0.8948,  ..., 0.9236, 1.0000, 1.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.4941, 0.8042, 0.7008,  ..., 0.7046, 0.7213, 0.7000],\n",
      "          [0.4630, 0.4232, 0.4215,  ..., 0.6646, 0.6715, 0.7116],\n",
      "          [0.5198, 0.6364, 0.5741,  ..., 0.5221, 0.6978, 0.7676],\n",
      "          ...,\n",
      "          [0.5919, 0.6023, 0.5406,  ..., 0.5682, 0.6786, 0.6779],\n",
      "          [0.3817, 0.5626, 0.6718,  ..., 0.5280, 0.5966, 0.5999],\n",
      "          [0.5940, 0.5714, 0.5062,  ..., 0.6195, 0.6065, 0.7382]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.7023, 0.8619, 0.6329,  ..., 0.7102, 0.8974, 0.6435],\n",
      "          [0.8330, 0.6176, 0.8855,  ..., 0.7882, 0.7582, 0.6954],\n",
      "          [0.7308, 0.7116, 0.8349,  ..., 0.7228, 0.7748, 0.7384],\n",
      "          ...,\n",
      "          [0.6598, 0.7080, 0.5197,  ..., 0.6651, 0.6982, 0.7189],\n",
      "          [0.7284, 0.7889, 0.6352,  ..., 0.6413, 0.6208, 0.8603],\n",
      "          [0.6343, 0.6546, 0.8408,  ..., 0.8352, 0.6473, 0.6898]]],\n",
      "\n",
      "\n",
      "        [[[0.5840, 0.7341, 0.5066,  ..., 0.3416, 0.5934, 0.4936],\n",
      "          [0.7190, 0.5582, 0.5715,  ..., 0.8364, 0.6871, 0.6538],\n",
      "          [0.5735, 0.6901, 0.6689,  ..., 0.5988, 0.6739, 0.7221],\n",
      "          ...,\n",
      "          [0.7659, 0.6514, 0.6306,  ..., 0.7848, 0.6125, 0.6893],\n",
      "          [0.6325, 0.7054, 0.7236,  ..., 0.7992, 0.6364, 0.9414],\n",
      "          [0.6186, 0.4472, 0.6923,  ..., 0.5969, 0.7560, 0.6601]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.8518, 0.8379,  ..., 0.7290, 0.8638, 0.8139],\n",
      "          [1.0000, 1.0000, 0.9074,  ..., 0.6564, 0.8326, 0.9995],\n",
      "          [0.9424, 0.8520, 0.9635,  ..., 0.9970, 0.9180, 0.7392],\n",
      "          ...,\n",
      "          [0.3390, 0.4232, 0.1589,  ..., 0.4135, 0.4518, 0.3264],\n",
      "          [0.3104, 0.4419, 0.5692,  ..., 0.3998, 0.4334, 0.2638],\n",
      "          [0.4122, 0.5869, 0.7502,  ..., 0.5054, 0.1524, 0.1506]]]])\n",
      "y batch: tensor([14, 18, 17,  7, 19,  3, 14, 20,  4, 20,  4, 20, 24, 14,  0,  5,  5,  2,\n",
      "        12, 12, 11,  7,  0, 13, 12, 11, 14,  4, 10,  0, 18,  0])\n"
     ]
    }
   ],
   "source": [
    "for X_batch, y_batch in test_loader:\n",
    "    print(\"X batch:\", X_batch)\n",
    "    print(\"y batch:\", y_batch)\n",
    "    break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "534"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AlexNet architecture\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_classes=26):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddu\\AppData\\Local\\Temp\\ipykernel_15508\\2453823309.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels, dtype=torch.long).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.763547610477562\n",
      "Epoch 2, Loss: 1.5188484206963122\n",
      "Epoch 3, Loss: 0.5341495398697111\n",
      "Epoch 4, Loss: 0.28531629010452453\n",
      "Epoch 5, Loss: 0.15577447173915532\n",
      "Epoch 6, Loss: 0.10665389693347381\n",
      "Epoch 7, Loss: 0.10711046971034299\n",
      "Epoch 8, Loss: 0.04698897054397966\n",
      "Epoch 9, Loss: 0.06163578690383941\n",
      "Epoch 10, Loss: 0.019740690448519473\n",
      "Training Finished\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "alexnet = AlexNet().to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(alexnet.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        \n",
    "        labels = torch.tensor(labels, dtype=torch.long).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = alexnet(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "print(\"Training Finished\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddu\\AppData\\Local\\Temp\\ipykernel_15508\\3622266950.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels, dtype=torch.long).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.018601914496087633\n",
      "Testing Finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_loss = 0.0\n",
    "\n",
    "alexnet.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, labels) in enumerate(test_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = torch.tensor(labels, dtype=torch.long).to(device)\n",
    "\n",
    "        outputs = alexnet(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "    print(f\"Test Loss: {test_loss/len(test_loader)}\")\n",
    "\n",
    "print(\"Testing Finished\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (inputs, labels) in enumerate(train_loader):\n",
    "    x = inputs\n",
    "    y = labels\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.7715, 0.6865, 0.6812,  ..., 0.6806, 0.5389, 0.7377],\n",
       "          [0.6986, 0.6114, 0.6447,  ..., 0.6901, 0.6221, 0.7035],\n",
       "          [0.7319, 0.7904, 0.6539,  ..., 0.6164, 0.5356, 0.7780],\n",
       "          ...,\n",
       "          [0.4942, 0.6172, 0.7665,  ..., 0.7386, 0.6654, 0.7681],\n",
       "          [0.5605, 0.6804, 0.7364,  ..., 0.7008, 0.5663, 0.8968],\n",
       "          [0.8412, 0.6651, 0.6954,  ..., 0.8065, 0.5904, 0.5897]]],\n",
       "\n",
       "\n",
       "        [[[0.5938, 0.6250, 0.5592,  ..., 0.4518, 0.5233, 0.5265],\n",
       "          [0.4965, 0.4231, 0.6035,  ..., 0.6708, 0.6504, 0.5599],\n",
       "          [0.6069, 0.8275, 0.3714,  ..., 0.4810, 0.5531, 0.5178],\n",
       "          ...,\n",
       "          [0.4504, 0.4527, 0.1572,  ..., 0.3042, 0.6319, 0.5215],\n",
       "          [0.6344, 0.5761, 0.6599,  ..., 0.4503, 0.3831, 0.5919],\n",
       "          [0.6859, 0.6490, 0.7449,  ..., 0.6597, 0.6909, 0.5773]]],\n",
       "\n",
       "\n",
       "        [[[0.5823, 0.7492, 0.5408,  ..., 0.7303, 0.6603, 0.6329],\n",
       "          [0.6405, 0.6578, 0.7967,  ..., 0.5867, 0.7847, 0.5877],\n",
       "          [0.6006, 0.5953, 0.5838,  ..., 0.7452, 0.6478, 0.6243],\n",
       "          ...,\n",
       "          [0.5896, 0.7149, 0.5778,  ..., 0.7111, 0.6805, 0.5878],\n",
       "          [0.5608, 0.4727, 0.6185,  ..., 0.6245, 0.5877, 0.5566],\n",
       "          [0.5429, 0.4799, 0.9138,  ..., 0.8504, 0.5301, 0.7154]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0.5998, 0.3553, 0.5076,  ..., 0.6432, 0.6364, 0.4252],\n",
       "          [0.3664, 0.4533, 0.4559,  ..., 0.5414, 0.5453, 0.5810],\n",
       "          [0.4926, 0.5548, 0.4482,  ..., 0.4765, 0.3907, 0.6220],\n",
       "          ...,\n",
       "          [0.5814, 0.6632, 0.5368,  ..., 0.5462, 0.5791, 0.6602],\n",
       "          [0.6342, 0.4552, 0.4200,  ..., 0.7098, 0.3722, 0.5537],\n",
       "          [0.4691, 0.6971, 0.4341,  ..., 0.4265, 0.4636, 0.3429]]],\n",
       "\n",
       "\n",
       "        [[[0.7964, 0.7994, 0.6792,  ..., 0.7045, 0.7315, 0.4602],\n",
       "          [0.5747, 0.5588, 0.6747,  ..., 0.6792, 0.7414, 0.7127],\n",
       "          [0.6826, 0.6787, 0.7975,  ..., 0.5382, 0.7024, 0.4208],\n",
       "          ...,\n",
       "          [0.5719, 0.5644, 0.6389,  ..., 0.7359, 0.6324, 0.6688],\n",
       "          [0.8843, 0.4058, 0.6902,  ..., 0.6609, 0.6723, 0.5557],\n",
       "          [0.6548, 0.6364, 0.7169,  ..., 0.6105, 0.6554, 0.8125]]],\n",
       "\n",
       "\n",
       "        [[[0.7473, 0.5756, 0.7867,  ..., 0.5703, 0.5594, 0.6164],\n",
       "          [0.5096, 0.7538, 0.8575,  ..., 0.6724, 0.7965, 0.5657],\n",
       "          [0.6884, 0.6735, 0.7270,  ..., 0.6768, 0.7995, 0.5467],\n",
       "          ...,\n",
       "          [0.8150, 0.6388, 0.8008,  ..., 0.5925, 0.6843, 0.7207],\n",
       "          [0.5880, 0.6703, 0.5912,  ..., 0.5703, 0.6703, 0.6806],\n",
       "          [0.7577, 0.8132, 0.7164,  ..., 0.6926, 0.8753, 0.6256]]]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(image_tensor):\n",
    "    # Ensure the input tensor is on the same device as the model\n",
    "    image_tensor = image_tensor.to(device)\n",
    "\n",
    "    # Perform the forward pass\n",
    "    with torch.no_grad():\n",
    "        output = alexnet(image_tensor)\n",
    "\n",
    "    return  chr(torch.argmax(output[0]).item() + ord('a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
